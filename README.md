# Azure Clinical Data Engineering POC (Free Tier)

**Endâ€‘toâ€‘end Azure data engineering project** that integrates 3 sources â€” **Database, API, and ADLS files** â€” and delivers analytics via a modern **Medallion Architecture (Bronze â†’ Silver â†’ Gold)** using **ADF, Databricks, Synapse (Serverless), and Power BI**. Built to run on the **Azure Free Tier** with minimal cost.

---

## ğŸš€ Quick Intro

This POC simulates a pharma/clinical scenario (e.g., Abbott) by ingesting:

* **Azure SQL DB** (trial subjects),
* **HTTP API** (Adverse Events via Azure Functions), and
* **ADLS files** (LOINCâ€‘coded Lab Results),
  then transforming in **Azure Databricks**, storing curated datasets in **ADLS**, exposing them via **Synapse Serverless**, and visualizing in **Power BI**.

**Highlights**

* 3 sources â†’ ADF orchestration with **Selfâ€‘Hosted IR**
* Databricks transformations + KPIs
* Synapse Serverless external tables over ADLS **Gold**
* Git integration across **ADF, Databricks, Synapse**
* Designed for **â‚¹0 using Free Tier credits**

---

## ğŸ§± Reference Architecture

```
Database (Azure SQL) â”€â”
API (Azure Function) â”€â”¼â”€> Azure Data Factory (Selfâ€‘Hosted IR + Autoâ€‘Resolve)
ADLS (CSV/JSON) â”€â”€â”€â”€â”€â”€â”˜            â”‚
                                   â–¼
                         ADLS Gen2 (Bronze)
                                   â–¼
                           Databricks (ETL)
                                   â–¼
                         ADLS Gen2 (Silver/Gold)
                                   â–¼
                        Synapse (Serverless SQL)
                                 
```



---

## ğŸ§° Azure Services Used

* **Azure SQL Database (Basic/Free Tier)** â€“ transactional source (trial subjects)
* **Azure Functions (HTTP Trigger)** â€“ simulated Adverse Events API
* **Azure Data Lake Storage Gen2** â€“ Raw/Silver/Gold zones
* **Azure Data Factory** â€“ ingestion, scheduling, Databricks notebook runs
* **Integration Runtime** â€“ **Selfâ€‘Hosted IR** (hybrid) + **Autoâ€‘Resolve IR**
* **Azure Databricks** â€“ transformations, joins, KPIs (Delta/Parquet)
* **Azure Synapse Analytics (Serverless SQL Pool)** â€“ external tables on Gold
* **Power BI** â€“ dashboards
* **GitHub** â€“ Git integration for ADF, Databricks, Synapse

---

## ğŸ—‚ï¸ Repo Structure

```
/README.md
/docs/architecture.png               # (optional) exported diagram                       # exported notebooks (ipynb/py)
/adf/
  linkedServices/                    # ARM/JSON
  datasets/
  pipelines/
/databricks/
  notebooks/                          
synapse/
  sqlscripts/                               # external table & view scripts
                        
```

---

## ğŸ“š Domain & Datasets (Samples)

**1) Trial Subjects (Database/CSV)**

* Columns: `subject_id, trial_id, site_id, enrollment_date, arm, sex, dob, country`

**2) Adverse Events (API/JSON)**

* Columns: `event_id, subject_id, trial_id, onset_date, resolved_date, preferred_term, severity, serious, relatedness, outcome`

**3) Lab Results (Files/CSV)**

* Columns: `lab_result_id, subject_id, encounter_id, order_datetime_utc, collected_datetime_utc, result_datetime_utc, loinc_code, test_name, result_value, unit, abnormal_flag, status, lab_vendor`

> Place sample files under `/data/raw/...` and register them in ADF.

---

## ğŸ§ª Medallion Layers

**Bronze (Raw)**

* Asâ€‘is copies of sources.
* Example paths: `/raw/trial_subjects/`, `/raw/adverse_events/`, `/raw/lab_results/` (partition by `ingest_date=`)

**Silver (Clean & Conform)**

* Standardized schemas, types, UTC timestamps, basic quality rules.
* Example outputs: `/silver/trial_subjects/`, `/silver/adverse_events/`, `/silver/lab_results/`

**Gold (Curated & KPIs)**

* Joined subjectâ€‘level and trialâ€‘level tables.
* Example outputs: `/gold/subject_summary/`, `/gold/trial_kpi/`, optional `/gold/ae_detail/`, `/gold/lab_detail/`

**Dataset Counts** *(example for POC)*

* Bronze: **3** datasets
* Silver: **3** datasets
* Gold: **2â€“4** datasets

---

## ğŸ”¢ KPIs (Examples)

* **Serious AE Rate (%)** = serious AEs / total AEs
* **Avg AE Duration (days)**
* **Abnormal Lab %** = abnormal tests / total tests
* **Mean Lab Result (per subject/trial)**
* **Subjects Enrolled (trial/site)**

---

## âš™ï¸ Setup & Run

### Prerequisites

* Azure subscription (Free Trial / credits)
* Resource Group + Region
* Contributor rights on RG

### 1) Provision Services (minimal cost)

* **ADLS Gen2** (Hierarchical Namespace = On)
* **Azure SQL Database** (Basic tier) + table for subjects
* **Azure Function** (Consumption plan) for AE API (HTTP trigger)
* **Databricks** (trial/small cluster; stop when idle)
* **Synapse Workspace** (use **Serverless SQL** only)
* **ADF** (Data Factory v2)

### 2) Integration Runtime

* Install & register **Selfâ€‘Hosted IR** on your machine (for local/secured sources)
* Use **Autoâ€‘Resolve IR** for cloudâ€‘toâ€‘cloud moves

### 3) Git Integration

* **ADF** â†’ Manage â†’ Git configuration â†’ connect GitHub repo/branch
* **Databricks** â†’ Repos â†’ connect Git (GitHub) for notebooks
* **Synapse** â†’ Manage â†’ Git configuration â†’ link repo for SQL scripts

### 4) Ingestion (ADF)

* Linked Services: Azure SQL, HTTP (Function), ADLS, Databricks, Synapse
* Datasets: CSV/JSON for files, REST for API, SQL for DB
* Pipelines:

  1. **Copy_SQL_to_ADLS** â†’ `/raw/trial_subjects/`
  2. **Copy_API_to_ADLS** â†’ `/raw/adverse_events/`
  3. **Copy_Files_to_ADLS** â†’ `/raw/lab_results/`
  4. **Run_Databricks_ETL** (notebook activity)
  5. **Refresh_Synapse_Metadata** (optional: SQL script)

### 5) Transformations (Databricks)

* **Silver:** type casting, UTC normalization, dedupe, data quality rules
* **Gold:** joins (subjects âŸ· labs âŸ· AEs), KPI calculations, write Parquet/Delta to `/gold`

### 6) Synapse (Serverless)

* Create **EXTERNAL DATA SOURCE** to ADLS Gold
* Define **EXTERNAL TABLES / VIEWS** over Parquet/Delta folders
* Validate with `SELECT TOP 100 * FROM dbo.subject_summary;`

### 7) Power BI

* Connect to Synapse (Serverless) or directly to ADLS Parquet
* Publish dashboards

---

## ğŸ” Security & Secrets

* Use **Key Vault** for connection strings & keys (optional in POC)
* RBAC on ADLS containers; Private Endpoints if required

---

## ğŸ’¸ Cost Tips

* Prefer **Serverless Synapse** (payâ€‘perâ€‘query)
* Use **Consumption plan** for Functions
* **Stop/terminate** Databricks clusters when idle
* Limit ADF triggers and pipeline runs

---

## âœ… Deliverables

* Automated pipelines (ADF)
* Cleaned Silver and curated Gold datasets in ADLS
* Synapse Serverless external tables
* Power BI dashboard(s)
* Git history for ADF, Databricks, and Synapse assets

---

## ğŸ“„ License

MIT (or your preferred license)

---

## ğŸ™‹ Support / Session

Interested in **building or learning** this kind of Azure project? Iâ€™m happy to help or run a short walkthrough session. Connect with me on LinkedIn or open an issue in this repo.
